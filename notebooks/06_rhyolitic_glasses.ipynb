{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhyolitic glasses from Mallik et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up to find custom python package\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1, \".\")\n",
    "sys.path.insert(1, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import readfiles, wdscan, correct_quant, calczaf, helper_funs\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nitrogen analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WD scan - visualise & fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplenames = [\"A870\", \"A876\", \"B989\"]\n",
    "metadata_list = {}\n",
    "data_list = {}\n",
    "\n",
    "for s in samplenames:\n",
    "    print(f\"---------------- {s} ----------------\")\n",
    "\n",
    "    folderpath = f\"../data/raw/rhyolitic_glasses_StA/{s}_long_scan\"\n",
    "    \n",
    "    # Read in the data\n",
    "    for d in [\"data001\", \"data002\"]:\n",
    "        try:             \n",
    "            comments, data, metadata = readfiles.import_jeol_wdscans(\n",
    "                subfolder=folderpath,\n",
    "                scan_filename=f'{d}_mm.csv',\n",
    "                cnd_filename=f'{d}.cnd',\n",
    "                comment_line_num=80,\n",
    "                crystal_line_name=\"$XM_WDS_CRYSTAL_NAME%0\",\n",
    "                sep=',',\n",
    "                return_metadata=True\n",
    "            )\n",
    "\n",
    "            metadata_list[s] = metadata\n",
    "            data_list[s] = data\n",
    "        except FileNotFoundError:\n",
    "                print(f\"No file found for {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(10, 3))\n",
    "ax.plot(data_list[\"A870\"].L, data_list[\"A870\"].cps_per_nA, label=\"A870\", lw=0.5)\n",
    "ax.plot(data_list[\"A876\"].L, data_list[\"A876\"].cps_per_nA, label=\"A876\", lw=0.5)\n",
    "ax.plot(data_list[\"B989\"].L, data_list[\"B989\"].cps_per_nA, label=\"B989\", lw=0.5)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all very similar. I think I could fit them all together and then treat these\n",
    "three glasses as a 'group' of samples. Maybe just aggregate the 146.6 and 146.4 versions too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, trimmed_data = wdscan.fit_scans_together(\n",
    "    data = list(data_list.values()),\n",
    "    fit_regions = [[120, 140], [152, 180]],\n",
    "    path_out = Path(\"../data/interim/rhyolitic_glasses/fits\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdscan.plot_fits_together(\n",
    "    data=list(data_list.values()),\n",
    "    trimmed_data=trimmed_data,\n",
    "    result=result,\n",
    "    comments=list(data_list.keys()),\n",
    "    path_out=Path(\"../data/interim/rhyolitic_glasses/fits\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those fits look good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['A870', 'A876', 'B989']\n",
    "sample_folders = [Path(f'../data/raw/rhyolitic_glasses_StA/quant/{s}/') for s in sample_list]\n",
    "# List of folders corresponding to the samples\n",
    "category = 'rhyolitic glasses' # Category of this dataset (e.g. \"glasses\")\n",
    "wd_scan = Path(f'../data/interim/rhyolitic_glasses/fits/key_params.txt') # Path to wd scan fit parameters\n",
    "std_dbase_info_file = Path('data/_dictionaries/standards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = readfiles.find_files_and_folders(\n",
    "                sample_list, sample_folders,\n",
    "                # apf_file = None,\n",
    "                apf_file=Path('../data/_dictionaries/apf_values.csv'), #<- Can put None in here\n",
    "                wd_scan=wd_scan\n",
    "                )\n",
    "\n",
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myspot = [None] * len(datalist.folder)\n",
    "\n",
    "for i in range(len(datalist.folder)):\n",
    "    peak, bg, standard, info = readfiles.read_and_organise_data(\n",
    "                                    datalist.loc[i,:].copy(),\n",
    "                                    bgi=False,\n",
    "                                    save=False)\n",
    "    myspot[i] = correct_quant.Spot()\n",
    "    myspot[i].add_data(info, bg, peak, standard)\n",
    "    myspot[i].add_wd_scan_params_from_file(wd_scan)\n",
    "    print('Read dataset:', i + 1, 'of', len(datalist), ':',\n",
    "          myspot[i].info.comment)\n",
    "    myspot[i].comprehensify_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_quant.process_datasets(\n",
    "    myspot, \n",
    "    datalist, \n",
    "    num_mc_sims=100, \n",
    "    path_out=Path(f\"../data/processed/rhyolitic_glasses/background_corrections\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write calczaf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_list\n",
    "subfolder = Path(f'../data/processed/rhyolitic_glasses/calczaf_files/')\n",
    "\n",
    "write_detection_limit_calczaf_files = True\n",
    "detlim_subfolder = subfolder / Path('detlim')\n",
    "\n",
    "# note: in the subfolder there must be a file specifying valence.\n",
    "# this can be copied from the _dictionaries folder.\n",
    "valence_dict = readfiles.read_valence_file(subfolder, pattern='valence*')\n",
    "standard_database_dict = pd.read_csv(\n",
    "    '../data/_dictionaries/standards.csv',\n",
    "     index_col=0, \n",
    "     header=None, \n",
    "     squeeze=True).to_dict()\n",
    "\n",
    "standard_database_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary\n",
    "# Separate the myspot list by sample\n",
    "sampledata = [None]*len(samples)\n",
    "for i, sample in enumerate(samples):\n",
    "    sampledata[i] = [spot for i, spot in enumerate(myspot) if sample == spot.info['sample']]\n",
    "\n",
    "sampledata = dict(zip(samples,sampledata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these glasses we did not do major element analyses, so we need to use\n",
    "literature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B989_majors = pd.DataFrame.from_dict(dict(\n",
    "    SiO2 = [67.9, 0.2],\n",
    "    TiO2 = [0.22, 0.3],\n",
    "    Al2O3 = [13.58, 0.09],\n",
    "    FeO = [0.01, 0.01],\n",
    "    MnO = [0.01, 0.01],\n",
    "    MgO = [0.25, 0.02],\n",
    "    CaO = [1.10, 0.04],\n",
    "    Na2O = [6.0, 0.1],\n",
    "    K2O = [2.40, 0.05],\n",
    "    P2O5 = [0.06, 0.04]\n",
    "), orient=\"index\", columns=[\"wt%\", \"stdev\"])\n",
    "\n",
    "A870_majors = pd.DataFrame.from_dict(dict(\n",
    "    SiO2 = [64.3, 0.3],\n",
    "    TiO2 = [0.21, 0.2],\n",
    "    Al2O3 = [13.8, 0.1],\n",
    "    FeO = [0.03, 0.02],\n",
    "    MnO = [0.03, 0.02],\n",
    "    MgO = [0.26, 0.02],\n",
    "    CaO = [1.07, 0.04],\n",
    "    Na2O = [5.45, 0.1],\n",
    "    K2O = [2.38, 0.04],\n",
    "    P2O5 = [0.05, 0.03]\n",
    "), orient=\"index\", columns=[\"wt%\", \"stdev\"])\n",
    "\n",
    "A876_majors = pd.DataFrame.from_dict(dict(\n",
    "    SiO2 = [63.4, 0.8],\n",
    "    TiO2 = [0.23, 0.3],\n",
    "    Al2O3 = [13.78, 0.01],\n",
    "    FeO = [0.01, 0.01],\n",
    "    MnO = [0.01, 0.01],\n",
    "    MgO = [0.26, 0.02],\n",
    "    CaO = [1.06, 0.03],\n",
    "    Na2O = [5.4, 0.4],\n",
    "    K2O = [2.39, 0.05],\n",
    "    P2O5 = [0.03, 0.02]\n",
    "), orient=\"index\", columns=[\"wt%\", \"stdev\"])\n",
    "\n",
    "majors_relevant_oxide = dict(zip([\"A870\", \"A876\", \"B989\"], [A870_majors, A876_majors, B989_majors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrolite.geochem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_relevant = {\n",
    "    k: v[[\"wt%\"]].T[[\"SiO2\", \"TiO2\", \"Al2O3\", \"FeO\", \"MnO\", \"MgO\", \"CaO\", \"Na2O\", \"K2O\", \"P2O5\"]]\n",
    "    .pyrochem.convert_chemistry(\n",
    "        to=[\"Si\", \"Ti\", \"Al\", \"Fe\", \"Mn\", \"Mg\", \"Ca\", \"Na\", \"K\", \"P\"]\n",
    "    )\n",
    "    .T.squeeze()\n",
    "    for k, v in majors_relevant_oxide.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_relevant[\"B989\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiple different methods of processing the data, add a description\n",
    "run_descriptor = ['_1_base', '_2_bg', '_3_bg_apf']  \n",
    "# Leave as a list of an empty string if not using: e.g. run_descriptor = ['']\n",
    "\n",
    "for i in range(len(samples)):\n",
    "\n",
    "    # Here we pass in these arguments as a dictionary - this is useful in order\n",
    "    # to reuse the arguments for the detection limit function. But you can\n",
    "    # alternatively pass in each argument just by defining it in the function\n",
    "    # as normal (see glasses example).\n",
    "\n",
    "    args = {\n",
    "              'elementByDifference' : 'h' # string element symbol\n",
    "            , 'elementByStoichToStoichOxygen' : None # string element symbol\n",
    "            , 'stoichOxygenRatio' : 0\n",
    "            # for hyalophane there is H\n",
    "            # that can be defined stoichiometrically relative to N:\n",
    "            , 'elementByStoichToOtherElement' : None\n",
    "            , 'OtherElement' : None\n",
    "            , 'stoichElementRatio' : None\n",
    "\n",
    "            , 'correct_bg' : False\n",
    "            , 'correct_apf' : False\n",
    "\n",
    "            # Elements to omit from matrix correction\n",
    "            # (e.g. if analysed but not actually present in sample)\n",
    "            , 'remove_elements' : None\n",
    "\n",
    "            , 'definedElements' : majors_relevant[samples[i]].index # list of element symbols to add\n",
    "            , 'definedElementWts' : majors_relevant[samples[i]].values # list of known element wt% to add\n",
    "            }\n",
    "    \n",
    "    # Make copies of args with different values\n",
    "    args2 = args.copy()\n",
    "    args2[\"correct_bg\"] = True\n",
    "    args2[\"correct_apf\"] = False\n",
    "\n",
    "    args3 = args2.copy()\n",
    "    args3[\"correct_bg\"] = True\n",
    "    args3[\"correct_apf\"] = True\n",
    "\n",
    "    args_list = [args, args2, args3]\n",
    "\n",
    "    for j in range(len(run_descriptor)):\n",
    "        print(\"******************************************************\")\n",
    "        print(args_list[j][\"correct_bg\"], args_list[j][\"correct_apf\"])\n",
    "        print(\"******************************************************\")\n",
    "\n",
    "        calczaf_path_out = subfolder / '{}{}.dat'.format(\n",
    "                                            samples[i], run_descriptor[j])\n",
    "        open(calczaf_path_out, 'w').close()  # Erase contents of file\n",
    "\n",
    "        if write_detection_limit_calczaf_files:\n",
    "            \n",
    "            detlim_path_out = detlim_subfolder / '{}{}_detlim.dat'.format(\n",
    "                                            samples[i], run_descriptor[j])\n",
    "            open(detlim_path_out, 'w').close()  # Erase contents of file\n",
    "\n",
    "        for spot in sampledata[samples[i]]:\n",
    "\n",
    "            calczaf.write_calczaf_input(\n",
    "                spot, calczaf_path_out, valence_dict, standard_database_dict,\n",
    "                accV=10, calcMode=2, taAngle=40, Oxide_or_Element=1,\n",
    "                **args_list[j]) # <- **args unpacks the args dictionary defined earlier\n",
    "                # so that all those arguments are passed into the function\n",
    "                # without the need to type them all out.\n",
    "\n",
    "            if write_detection_limit_calczaf_files:\n",
    "                if args_list[j]['correct_bg']:\n",
    "\n",
    "                    detlim_spot = correct_quant.create_detection_limit_spot(spot)\n",
    "\n",
    "                    calczaf.write_calczaf_input(\n",
    "                        detlim_spot, detlim_path_out, valence_dict, \n",
    "                        standard_database_dict,\n",
    "                        accV=10, calcMode=2, taAngle=40, Oxide_or_Element=1,\n",
    "                        **args_list[j])\n",
    "                    \n",
    "                else:\n",
    "                    print('\\n\\nWarning: Not writing detection limit file.' \n",
    "                            'Calculating detection limit does not make sense'\n",
    "                            ' except on background-corrected data. Raw data files' \n",
    "                            ' contain an estimate of detection limit without bg'\n",
    "                            ' correction.\\n')\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process calczaf outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = Path(f'../data/processed/rhyolitic_glasses/calczaf_files/')\n",
    "\n",
    "helper_funs.check_calczaf_folder_exists(folderpath)\n",
    "valence_file = sorted(folderpath.glob('valence*'))[0]\n",
    "\n",
    "results = calczaf.process_calczaf_outputs(folderpath, valence_file)\n",
    "\n",
    "# For detection limits\n",
    "\n",
    "results_detlim = calczaf.process_calczaf_outputs(folderpath / 'detlim/', valence_file, detlim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tables = {}\n",
    "typical_kratios = {}\n",
    "\n",
    "for s in samples:\n",
    "    summary_tables[s] = correct_quant.write_summary_excel_tables(\n",
    "        sampledata[s], \n",
    "        f\"../data/processed/rhyolitic_glasses/kraw_summaries_{s}.xlsx\"\n",
    "        )\n",
    "    \n",
    "    typical_kratios[s] = pd.DataFrame({\n",
    "        \"K-ratio\": [\n",
    "            summary_tables[s][0][\"original.kraw_pcnt\"].mean(),\n",
    "            summary_tables[s][0][\"montecarlo.kraw_pcnt\"].mean(),\n",
    "            summary_tables[s][0][\"montecarlo.kraw_apf_pcnt\"].mean()\n",
    "        ],\n",
    "        \"Stdev % (relative)\": [\n",
    "            max(\n",
    "                summary_tables[s][0][\"original.kraw_stdev_pcnt\"].mean(),\n",
    "                summary_tables[s][0][\"original.kraw_pcnt\"].std()\n",
    "                ),\n",
    "            max(\n",
    "                summary_tables[s][0][\"montecarlo.kraw_stdev_pcnt\"].mean(),\n",
    "                summary_tables[s][0][\"montecarlo.kraw_pcnt\"].std()\n",
    "                ),\n",
    "            max(\n",
    "                summary_tables[s][0][\"montecarlo.kraw_stdev_apf_pcnt\"].mean(),\n",
    "                summary_tables[s][0][\"montecarlo.kraw_apf_pcnt\"].std()\n",
    "                )\n",
    "        ]\n",
    "    }, index = [\n",
    "        \"Original K-ratio (%)\", \n",
    "        \"Bg-corrected K-ratio (%)\", \n",
    "        \"Bg- and APF-corrected K-ratio (%)\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    typical_kratios[s].insert(\n",
    "        1, \n",
    "        column=\"Stdev (absolute)\", \n",
    "        value = typical_kratios[s][\"K-ratio\"] * typical_kratios[s][\"Stdev % (relative)\"] / 100\n",
    "        )\n",
    "    \n",
    "    typical_kratios[s][\"filename\"] = [k for k in results[\"wtdata\"].keys() if s in k]\n",
    "    typical_kratios[s].reset_index(inplace=True)\n",
    "    typical_kratios[s].set_index(\"filename\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typical_kratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all spots grouped by their method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"3_bg_apf\"\n",
    "stdev_string = \"kraw_stdev_apf_pcnt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_apf = {k: v.loc[\"N\", :] for k, v in results[\"wtdata\"].items() if suffix in k}\n",
    "results_detlim_apf = {k: v.loc[\"N\", :] for k, v in results_detlim[\"wtdata\"].items() if suffix in k}\n",
    "\n",
    "results_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_apf.items()\n",
    "}\n",
    "\n",
    "results_detlim_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_detlim_apf.items()\n",
    "}\n",
    "\n",
    "for k, v in results_apf.items():\n",
    "    v.name = \"N wt\"\n",
    "\n",
    "for k, v in results_detlim_apf.items():\n",
    "    v.name = \"N detlim\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist_by_sample= dict(list(datalist.groupby(\"sample\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_by_method = {}\n",
    "for s in samples:\n",
    "    N_by_method[s] = pd.DataFrame(\n",
    "        {\n",
    "            \"comment\": datalist_by_sample[s][\"comment\"].reset_index(drop=True),\n",
    "            \"N wt\": results_apf[f\"{s}_3_bg_apf\"],\n",
    "            \"N detlim\": results_detlim_apf[f\"{s}_3_bg_apf_detlim\"],\n",
    "            \"N stdev pct\": summary_tables[s][0][f\"montecarlo.{stdev_string}\"],\n",
    "            \"N stdev abs\": (\n",
    "                results_apf[f\"{s}_3_bg_apf\"]\n",
    "                * summary_tables[s][0][f\"montecarlo.{stdev_string}\"]\n",
    "                / 100\n",
    "            )\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samples:\n",
    "    display(N_by_method[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a figure showing all quant values against reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = pd.concat(\n",
    "        [N_by_method[s].loc[:, [\"N wt\", \"N stdev abs\"]].mean() for s in samples],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "avgs.columns = samples\n",
    "avgs.columns.name = \"sample_name\"\n",
    "avgs = avgs.T.reset_index()\n",
    "\n",
    "avgs = avgs.rename(columns = {\"N wt\": \"measured\", \"N stdev abs\": \"measured_stdev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note!!! the stdev on multiple measurements is smaller than the stdev on individual ones.\n",
    "So we'll report the typical stdev on single measurements - this includes the uncertainty on APF propoagated through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_vals = pd.DataFrame({\n",
    "    \"sample_name\": [\"A870\", \"A876\", \"B989\"],\n",
    "    \"reference\": [1.0, 0.5, 0.9],\n",
    "    \"reference_stdev\": [0.4, 0.3, 0.3],\n",
    "})\n",
    "\n",
    "glasses_avgs = pd.merge(reference_vals, avgs, on = \"sample_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3), )\n",
    "\n",
    "ax.errorbar(\n",
    "    x=glasses_avgs[\"reference\"], \n",
    "    xerr=glasses_avgs[\"reference_stdev\"],\n",
    "    y=glasses_avgs[\"measured\"],\n",
    "    yerr=glasses_avgs[\"measured_stdev\"],\n",
    "    fmt=\"ok\")\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "line_min, line_max = (min(xmin, ymin), max(xmax, ymax))\n",
    "ax.plot([xmin, xmax], [xmin, xmax], \"-r\", linewidth=0.5)\n",
    "\n",
    "label_locs = [\n",
    "    (1.2, 0.9), #A870\n",
    "    (0.3, 0.8), #A876\n",
    "    (0.7, 1.3), #B989\n",
    "]\n",
    "\n",
    "for i in range(len(glasses_avgs.index)):\n",
    "    x = glasses_avgs.loc[i, \"reference\"]\n",
    "    y = glasses_avgs.loc[i, \"measured\"]\n",
    "    ax.annotate(\n",
    "        glasses_avgs.loc[i, \"sample_name\"], \n",
    "        (x,y), \n",
    "        xytext=label_locs[i], ha=\"center\",\n",
    "        # arrowprops={\"arrowstyle\": \"->\"},\n",
    "        bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.5))\n",
    "    \n",
    "plt.ylabel(\"N wt% (EPMA)\")\n",
    "plt.xlabel(\"N wt% (literature)\")\n",
    "plt.xticks(np.arange(0, 2.0, 0.5))\n",
    "plt.yticks(np.arange(0, 2.0, 0.5))\n",
    "plt.xlim(line_min, line_max)\n",
    "plt.ylim(line_min, line_max)\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/processed/rhyolitic_glasses/epma_vs_reference.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"1_base\"\n",
    "stdev_string = \"original.kraw_stdev_pcnt\"\n",
    "results_apf = {k: v.loc[\"N\", :] for k, v in results[\"wtdata\"].items() if suffix in k}\n",
    "results_detlim_apf = {k: v.loc[\"N\", :] for k, v in results_detlim[\"wtdata\"].items() if suffix in k}\n",
    "\n",
    "results_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_apf.items()\n",
    "}\n",
    "\n",
    "results_detlim_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_detlim_apf.items()\n",
    "}\n",
    "\n",
    "for k, v in results_apf.items():\n",
    "    v.name = \"N wt\"\n",
    "\n",
    "for k, v in results_detlim_apf.items():\n",
    "    v.name = \"N detlim\"\n",
    "\n",
    "datalist_by_sample= dict(list(datalist.groupby(\"sample\")))\n",
    "\n",
    "N_by_method = {}\n",
    "for s in samples:\n",
    "    N_by_method[s] = pd.DataFrame(\n",
    "        {\n",
    "            \"comment\": datalist_by_sample[s][\"comment\"].reset_index(drop=True),\n",
    "            \"N wt\": results_apf[f\"{s}_{suffix}\"],\n",
    "            \"N stdev pct\": summary_tables[s][0][f\"{stdev_string}\"],\n",
    "            \"N stdev abs\": (\n",
    "                results_apf[f\"{s}_{suffix}\"]\n",
    "                * summary_tables[s][0][f\"{stdev_string}\"]\n",
    "                / 100\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.concat(N_by_method, axis=0).reset_index()\n",
    "df_base = df.rename(columns = {\"level_0\": \"sample\"}).groupby(\"sample\")[[\"N wt\", \"N stdev abs\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"2_bg\"\n",
    "stdev_string = \"montecarlo.kraw_stdev_pcnt\"\n",
    "results_apf = {k: v.loc[\"N\", :] for k, v in results[\"wtdata\"].items() if suffix in k}\n",
    "results_detlim_apf = {k: v.loc[\"N\", :] for k, v in results_detlim[\"wtdata\"].items() if suffix in k}\n",
    "\n",
    "results_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_apf.items()\n",
    "}\n",
    "\n",
    "results_detlim_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_detlim_apf.items()\n",
    "}\n",
    "\n",
    "for k, v in results_apf.items():\n",
    "    v.name = \"N wt\"\n",
    "\n",
    "for k, v in results_detlim_apf.items():\n",
    "    v.name = \"N detlim\"\n",
    "\n",
    "datalist_by_sample= dict(list(datalist.groupby(\"sample\")))\n",
    "\n",
    "N_by_method = {}\n",
    "for s in samples:\n",
    "    N_by_method[s] = pd.DataFrame(\n",
    "        {\n",
    "            \"comment\": datalist_by_sample[s][\"comment\"].reset_index(drop=True),\n",
    "            \"N wt\": results_apf[f\"{s}_{suffix}\"],\n",
    "            \"N stdev pct\": summary_tables[s][0][f\"{stdev_string}\"],\n",
    "            \"N stdev abs\": (\n",
    "                results_apf[f\"{s}_{suffix}\"]\n",
    "                * summary_tables[s][0][f\"{stdev_string}\"]\n",
    "                / 100\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.concat(N_by_method, axis=0).reset_index()\n",
    "df_bg = df.rename(columns = {\"level_0\": \"sample\"}).groupby(\"sample\")[[\"N wt\", \"N stdev abs\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"3_bg_apf\"\n",
    "stdev_string = \"montecarlo.kraw_stdev_apf_pcnt\"\n",
    "results_apf = {k: v.loc[\"N\", :] for k, v in results[\"wtdata\"].items() if suffix in k}\n",
    "results_detlim_apf = {k: v.loc[\"N\", :] for k, v in results_detlim[\"wtdata\"].items() if suffix in k}\n",
    "\n",
    "results_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_apf.items()\n",
    "}\n",
    "\n",
    "results_detlim_apf = {\n",
    "    k: v.loc[\n",
    "        [c for c in v.index if c not in [\"average\", \"stdev\", \"minimum\", \"maximum\"]]\n",
    "    ]\n",
    "    for k, v in results_detlim_apf.items()\n",
    "}\n",
    "\n",
    "for k, v in results_apf.items():\n",
    "    v.name = \"N wt\"\n",
    "\n",
    "for k, v in results_detlim_apf.items():\n",
    "    v.name = \"N detlim\"\n",
    "\n",
    "datalist_by_sample= dict(list(datalist.groupby(\"sample\")))\n",
    "\n",
    "N_by_method = {}\n",
    "for s in samples:\n",
    "    N_by_method[s] = pd.DataFrame(\n",
    "        {\n",
    "            \"comment\": datalist_by_sample[s][\"comment\"].reset_index(drop=True),\n",
    "            \"N wt\": results_apf[f\"{s}_{suffix}\"],\n",
    "            \"N stdev pct\": summary_tables[s][0][f\"{stdev_string}\"],\n",
    "            \"N stdev abs\": (\n",
    "                results_apf[f\"{s}_{suffix}\"]\n",
    "                * summary_tables[s][0][f\"{stdev_string}\"]\n",
    "                / 100\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.concat(N_by_method, axis=0).reset_index()\n",
    "df_bg_apf = df.rename(columns = {\"level_0\": \"sample\"}).groupby(\"sample\")[[\"N wt\", \"N stdev abs\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = pd.concat([df_base, df_bg, df_bg_apf], axis=1)\n",
    "final_summary.columns = [\"base\", \"base stdev\", \"bg\", \"bg stdev\", \"bg apf\", \"bg apf stdev\"]\n",
    "final_summary.round(2).to_csv(\"../data/processed/rhyolitic_glasses/N_summary.csv\")\n",
    "final_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n_epma_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
