{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic basaltic glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up to find custom python package\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1, \".\")\n",
    "sys.path.insert(1, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import readfiles, wdscan, correct_quant, calczaf, helper_funs\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference: how to rename folders\n",
    "\n",
    "# from src.readfiles import rename_folders_as_comments\n",
    "\n",
    "# for f in os.listdir(\"../data/raw/basaltic_glasses_StA/raw_quant_20211222/original/\"):\n",
    "#     print(f)\n",
    "                    \n",
    "#     rename_folders_as_comments(\n",
    "#         Path(f\"../data/raw/basaltic_glasses_StA/raw_quant_20211222/original/{f}\"), \n",
    "#         \"../data/raw/basaltic_glasses_StA/raw_quant_20211222/renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrolite.geochem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major/trace elements other than N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_major_elements_from_txt(path):\n",
    "\n",
    "    majors_raw = pd.read_csv(\n",
    "        path,\n",
    "        header=1,\n",
    "        index_col=False\n",
    "        )[:5]\n",
    "\n",
    "    mass_pct_cols = [col for col in majors_raw.columns if \"(Mass%)\" in col]\n",
    "    majors = majors_raw.loc[:, mass_pct_cols].rename(columns={col: col.replace(\"(Mass%)\", \"\") for col in mass_pct_cols})\n",
    "    detlims = majors_raw[[col for col in majors_raw.columns if \"(D.L.)\" in col]]\n",
    "    return majors, detlims\n",
    "\n",
    "majors = {}\n",
    "detlims = {}\n",
    "for s in [\"Edi06\", \"Edi09\", \"D2872\"]:\n",
    "\n",
    "    majors[s], detlims[s] = get_major_elements_from_txt(\n",
    "        f\"../data/raw/basaltic_glasses_StA/majors_20211110/{s.lower()}_all.txt\"\n",
    "    )\n",
    "\n",
    "# for D2983 I didn't get an \"_all.txt\" file so I need to get the data differently\n",
    "\n",
    "majors[\"D2893\"] = pd.read_csv(\n",
    "    \"../data/raw/basaltic_glasses_StA/majors_20211110/D2893_2_oxide.csv\",\n",
    "    header=1,\n",
    "    index_col=False\n",
    ")[:4]\n",
    "\n",
    "majors[\"D2893\"].columns = [c.strip() for c in majors[\"D2893\"].columns]\n",
    "\n",
    "detlims[\"D2893\"] = pd.read_csv(\n",
    "    \"../data/raw/basaltic_glasses_StA/majors_20211110/D2893_2_detlim.txt\",\n",
    "    header=1,\n",
    "    index_col=False\n",
    ")[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors[\"D2872\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors[\"D2893\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_element = {}\n",
    "\n",
    "for k, df in majors.items():\n",
    "\n",
    "    majors_element[k] = df[\n",
    "        ['SiO2', 'Al2O3', 'Cl', 'P2O5', 'Fe2O3', 'MnO', 'Cr2O3', 'K2O', 'CaO', 'Ru2O3', 'Na2O', 'MgO']\n",
    "        ].pyrochem.convert_chemistry(\n",
    "        to=['Si', 'Al', 'Cl', 'P', 'Fe', 'Mn', 'Cr', 'K', 'Ca', 'Ru', 'Na', 'Mg']\n",
    "    ).fillna(0)\n",
    "\n",
    "    majors_element[k][\"O\"] = df[\"Total\"] - (majors_element[k].sum(axis=1))\n",
    "\n",
    "    majors_element[k][\"Total\"] = majors_element[k].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_summary = {}\n",
    "\n",
    "for k, df in majors_element.items():\n",
    "    majors_summary[k] = pd.concat([df.T.mean(axis=1), df.T.std(axis=1)], axis=1)\n",
    "    majors_summary[k].columns = [\"wt% mean\", \"stdev\"]\n",
    "\n",
    "majors_summary_combined = pd.concat(majors_summary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_summary_combined.round(3).to_csv(\"../data/processed/basaltic_glasses/basaltic_glasses_majors_summary.csv\")\n",
    "majors_summary_combined.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detlims[\"Edi09\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nitrogen analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WD scan - visualise & fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D2872 - all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplenames = [\"D2872\", \"D2893\", \"Edi09\", \"Edi06\"]\n",
    "metadata_list = {}\n",
    "data_list = {}\n",
    "\n",
    "for s in samplenames:\n",
    "    print(f\"---------------- {s} ----------------\")\n",
    "\n",
    "    folderpath_list = [\n",
    "        f\"../data/raw/basaltic_glasses_StA/wd_scans_20211008/{s}\",\n",
    "        f\"../data/raw/basaltic_glasses_StA/wd_scans_20211125/{s}\",\n",
    "        f\"../data/raw/basaltic_glasses_StA/wd_scans_20211222/{s}\"\n",
    "    ]\n",
    "\n",
    "    metadata_list[s] = []\n",
    "    data_list[s] = []\n",
    "\n",
    "    for i, f in enumerate(folderpath_list):\n",
    "        # Read in the data\n",
    "        for d in [\"data001\", \"data002\"]:\n",
    "            try:             \n",
    "                comments, data, metadata = readfiles.import_jeol_wdscans(\n",
    "                    subfolder=f,\n",
    "                    scan_filename=f'{d}_mm.csv',\n",
    "                    cnd_filename=f'{d}.cnd',\n",
    "                    comment_line_num=80,\n",
    "                    crystal_line_name=\"$XM_WDS_CRYSTAL_NAME%0\",\n",
    "                    sep=',',\n",
    "                    return_metadata=True\n",
    "                )\n",
    "\n",
    "                metadata_list[s].append(metadata)\n",
    "                data_list[s].append(data)\n",
    "            except FileNotFoundError:\n",
    "                 print(f\"No file found for {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lde1l_scans = {}\n",
    "lde1_scans = {}\n",
    "\n",
    "for s in samplenames:\n",
    "    print(f\"--------------------{s}-------------------\")\n",
    "    lde1l_scans[s] = {\"metadata\": [], \"data\": []}\n",
    "    lde1_scans[s] = {\"metadata\": [], \"data\": []}\n",
    "\n",
    "    for i in range(len(data_list[s])):\n",
    "        if metadata_list[s][i].crystal == \"LDE1L\":\n",
    "            lde1l_scans[s][\"metadata\"].append(metadata_list[s][i])\n",
    "            lde1l_scans[s][\"data\"].append(data_list[s][i])\n",
    "\n",
    "        if metadata_list[s][i].crystal == \"LDE1\":\n",
    "            lde1_scans[s][\"metadata\"].append(metadata_list[s][i])\n",
    "            lde1_scans[s][\"data\"].append(data_list[s][i])    \n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=4, figsize=(10, 3))\n",
    "\n",
    "    for i in range(len(lde1l_scans[s][\"data\"])):\n",
    "            data = lde1l_scans[s][\"data\"][i]\n",
    "\n",
    "            ax[i].plot(data.L, data.cps_per_nA, \".k\", markersize=1)\n",
    "            ax[i].set_title(s)\n",
    "\n",
    "            ax[3].plot(data.L, data.cps_per_nA, \".\", markersize=1, label=i)\n",
    "            ax[3].set_title(\"All scans overlain\")\n",
    "\n",
    "    display(pd.DataFrame(lde1l_scans[s][\"metadata\"]).T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these, we can just fit the middle scan - the highest-resolution one\n",
    "Except for Edi06 for which there is only a single scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot with the fits ------------\n",
    "# Choose parts of the spectrum to use in the fit\n",
    "bg_roi = [[120,138], [155, 180]]\n",
    "sample = \"D2872\"\n",
    "\n",
    "comments, data, metadata = readfiles.import_jeol_wdscans(\n",
    "    subfolder=\"../data/raw/basaltic_glasses_StA/wd_scans_20211125/D2872\",\n",
    "    scan_filename='data001_mm.csv',\n",
    "    cnd_filename='data001.cnd',\n",
    "    comment_line_num=80,\n",
    "    crystal_line_name=\"$XM_WDS_CRYSTAL_NAME%0\",\n",
    "    sep=',',\n",
    "    return_metadata=True\n",
    ")\n",
    "print(metadata.crystal)\n",
    "trimmed_data = wdscan.trim_data_from_regions(data, bg_roi)\n",
    "out = wdscan.fit_bg(trimmed_data)\n",
    "wdscan.plot_bg_fit(data, trimmed_data, out, sample, [146.6], save_to=Path(\"../data/interim/basaltic_glasses/fits\"))\n",
    "par_dict = wdscan.write_fit_params(out, sample, save_to=Path(\"../data/interim/basaltic_glasses/fits/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D2983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot with the fits ------------\n",
    "# Choose parts of the spectrum to use in the fit\n",
    "bg_roi = [[120,140], [170, 180]]\n",
    "sample = \"D2893\"\n",
    "\n",
    "comments, data, metadata = readfiles.import_jeol_wdscans(\n",
    "    subfolder=\"../data/raw/basaltic_glasses_StA/wd_scans_20211125/D2893\",\n",
    "    scan_filename='data001_mm.csv',\n",
    "    cnd_filename='data001.cnd',\n",
    "    comment_line_num=80,\n",
    "    crystal_line_name=\"$XM_WDS_CRYSTAL_NAME%0\",\n",
    "    sep=',',\n",
    "    return_metadata=True\n",
    ")\n",
    "\n",
    "print(metadata.crystal)\n",
    "trimmed_data = wdscan.trim_data_from_regions(data, bg_roi)\n",
    "out = wdscan.fit_bg(trimmed_data)\n",
    "wdscan.plot_bg_fit(data, trimmed_data, out, sample, [146.6], save_to=Path(\"../data/interim/basaltic_glasses/fits\"))\n",
    "par_dict = wdscan.write_fit_params(out, sample, save_to=Path(\"../data/interim/basaltic_glasses/fits/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edi09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot with the fits ------------\n",
    "# Choose parts of the spectrum to use in the fit\n",
    "bg_roi = [[120,140], [170, 180]]\n",
    "sample = \"Edi09\"\n",
    "\n",
    "comments, data, metadata = readfiles.import_jeol_wdscans(\n",
    "    subfolder=\"../data/raw/basaltic_glasses_StA/wd_scans_20211125/Edi09\",\n",
    "    scan_filename='data001_mm.csv',\n",
    "    cnd_filename='data001.cnd',\n",
    "    comment_line_num=80,\n",
    "    crystal_line_name=\"$XM_WDS_CRYSTAL_NAME%0\",\n",
    "    sep=',',\n",
    "    return_metadata=True\n",
    ")\n",
    "\n",
    "print(metadata.crystal)\n",
    "trimmed_data = wdscan.trim_data_from_regions(data, bg_roi)\n",
    "out = wdscan.fit_bg(trimmed_data)\n",
    "wdscan.plot_bg_fit(data, trimmed_data, out, sample, [146.6], save_to=Path(\"../data/interim/basaltic_glasses/fits\"))\n",
    "par_dict = wdscan.write_fit_params(out, sample, save_to=Path(\"../data/interim/basaltic_glasses/fits/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edi06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot with the fits ------------\n",
    "# Choose parts of the spectrum to use in the fit\n",
    "bg_roi = [[120,140], [170, 180]]\n",
    "sample = \"Edi06\"\n",
    "\n",
    "comments, data, metadata = readfiles.import_jeol_wdscans(\n",
    "    subfolder=\"../data/raw/basaltic_glasses_StA/wd_scans_20211222/Edi06\",\n",
    "    scan_filename='data001_mm.csv',\n",
    "    cnd_filename='data001.cnd',\n",
    "    comment_line_num=80,\n",
    "    crystal_line_name=\"$XM_WDS_CRYSTAL_NAME%0\",\n",
    "    sep=',',\n",
    "    return_metadata=True\n",
    ")\n",
    "\n",
    "print(metadata.crystal)\n",
    "trimmed_data = wdscan.trim_data_from_regions(data, bg_roi)\n",
    "out = wdscan.fit_bg(trimmed_data)\n",
    "wdscan.plot_bg_fit(data, trimmed_data, out, sample, [146.6], save_to=Path(\"../data/interim/basaltic_glasses/fits\"))\n",
    "par_dict = wdscan.write_fit_params(out, sample, save_to=Path(\"../data/interim/basaltic_glasses/fits/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['D2872'] # List of samples in this dataset\n",
    "sample_folders = [Path('../data/raw/basaltic_glasses_StA/raw_quant_by_sample/D2872/')]\n",
    "# List of folders corresponding to the samples\n",
    "category = 'basaltic glasses' # Category of this dataset (e.g. \"glasses\")\n",
    "wd_scan = Path('../data/interim/basaltic_glasses/fits/key_params_D2872.txt') # Path to wd scan fit parameters\n",
    "std_dbase_info_file = Path('data/_dictionaries/standards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = readfiles.find_files_and_folders(\n",
    "                samples, sample_folders,\n",
    "                # apf_file = None,\n",
    "                apf_file=Path('../data/_dictionaries/apf_values.csv'), #<- Can put None in here\n",
    "                wd_scan=wd_scan\n",
    "                )\n",
    "\n",
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myspot = [None] * len(datalist.folder)\n",
    "\n",
    "for i in range(len(datalist.folder)):\n",
    "    peak, bg, standard, info = readfiles.read_and_organise_data(\n",
    "                                    datalist.loc[i,:].copy(),\n",
    "                                    bgi=False,\n",
    "                                    save=False)\n",
    "    myspot[i] = correct_quant.Spot()\n",
    "    myspot[i].add_data(info, bg, peak, standard)\n",
    "    myspot[i].add_wd_scan_params_from_file(wd_scan)\n",
    "    print('Read dataset:', i + 1, 'of', len(datalist), ':',\n",
    "          myspot[i].info.comment)\n",
    "    myspot[i].comprehensify_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_quant.process_datasets(\n",
    "    myspot, \n",
    "    datalist, \n",
    "    num_mc_sims=100, \n",
    "    path_out=Path(\"../data/processed/basaltic_glasses/background_corrections/D2872\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write calczaf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['D2872']\n",
    "category = 'basaltic glasses'\n",
    "subfolder = Path('../data/processed/basaltic_glasses/calczaf_files/D2872/')\n",
    "\n",
    "write_detection_limit_calczaf_files = True\n",
    "detlim_subfolder = subfolder / Path('detlim')\n",
    "\n",
    "# note: in the subfolder there must be a file specifying valence.\n",
    "# this can be copied from the _dictionaries folder.\n",
    "valence_dict = readfiles.read_valence_file(subfolder, pattern='valence*')\n",
    "standard_database_dict = pd.read_csv(\n",
    "    '../data/_dictionaries/standards.csv',\n",
    "     index_col=0, \n",
    "     header=None, \n",
    "     squeeze=True).to_dict()\n",
    "\n",
    "standard_database_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary\n",
    "sampledata = {\"D2872\": myspot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use actual analyses from StA\n",
    "majors_relevant = majors_summary[\"D2872\"].loc[\n",
    "    majors_summary[\"D2872\"].index[~majors_summary[\"D2872\"].index.isin([\"O\", \"Total\"])],\n",
    "    \"wt% mean\",\n",
    "]\n",
    "majors_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiple different methods of processing the data, add a description\n",
    "run_descriptor = ['_1_base', '_2_bg', '_3_bg_apf']  \n",
    "# Leave as a list of an empty string if not using: e.g. run_descriptor = ['']\n",
    "\n",
    "for i in range(len(samples)):\n",
    "\n",
    "    # Here we pass in these arguments as a dictionary - this is useful in order\n",
    "    # to reuse the arguments for the detection limit function. But you can\n",
    "    # alternatively pass in each argument just by defining it in the function\n",
    "    # as normal (see glasses example).\n",
    "\n",
    "    args = {\n",
    "              'elementByDifference' : 'h' # string element symbol\n",
    "            , 'elementByStoichToStoichOxygen' : None # string element symbol\n",
    "            , 'stoichOxygenRatio' : 0\n",
    "            # for hyalophane there is H\n",
    "            # that can be defined stoichiometrically relative to N:\n",
    "            , 'elementByStoichToOtherElement' : None\n",
    "            , 'OtherElement' : None\n",
    "            , 'stoichElementRatio' : None\n",
    "\n",
    "            , 'correct_bg' : False\n",
    "            , 'correct_apf' : False\n",
    "\n",
    "            # Elements to omit from matrix correction\n",
    "            # (e.g. if analysed but not actually present in sample)\n",
    "            , 'remove_elements' : None\n",
    "\n",
    "            , 'definedElements' : majors_relevant.index # list of element symbols to add\n",
    "            , 'definedElementWts' : majors_relevant.values # list of known element wt% to add\n",
    "            }\n",
    "    \n",
    "    # Make copies of args with different values\n",
    "    args2 = args.copy()\n",
    "    args2[\"correct_bg\"] = True\n",
    "    args2[\"correct_apf\"] = False\n",
    "\n",
    "    args3 = args2.copy()\n",
    "    args3[\"correct_bg\"] = True\n",
    "    args3[\"correct_apf\"] = True\n",
    "\n",
    "    args_list = [args, args2, args3]\n",
    "\n",
    "    for j in range(len(run_descriptor)):\n",
    "        print(\"******************************************************\")\n",
    "        print(args_list[j][\"correct_bg\"], args_list[j][\"correct_apf\"])\n",
    "        print(\"******************************************************\")\n",
    "\n",
    "        calczaf_path_out = subfolder / '{}{}.dat'.format(\n",
    "                                            samples[i], run_descriptor[j])\n",
    "        open(calczaf_path_out, 'w').close()  # Erase contents of file\n",
    "\n",
    "        if write_detection_limit_calczaf_files:\n",
    "            \n",
    "            detlim_path_out = detlim_subfolder / '{}{}_detlim.dat'.format(\n",
    "                                            samples[i], run_descriptor[j])\n",
    "            open(detlim_path_out, 'w').close()  # Erase contents of file\n",
    "\n",
    "        for spot in sampledata[samples[i]]:\n",
    "\n",
    "            calczaf.write_calczaf_input(\n",
    "                spot, calczaf_path_out, valence_dict, standard_database_dict,\n",
    "                accV=10, calcMode=2, taAngle=40, Oxide_or_Element=1,\n",
    "                **args_list[j]) # <- **args unpacks the args dictionary defined earlier\n",
    "                # so that all those arguments are passed into the function\n",
    "                # without the need to type them all out.\n",
    "\n",
    "            if write_detection_limit_calczaf_files:\n",
    "                if args_list[j]['correct_bg']:\n",
    "\n",
    "                    detlim_spot = correct_quant.create_detection_limit_spot(spot)\n",
    "\n",
    "                    calczaf.write_calczaf_input(\n",
    "                        detlim_spot, detlim_path_out, valence_dict, \n",
    "                        standard_database_dict,\n",
    "                        accV=10, calcMode=2, taAngle=40, Oxide_or_Element=1,\n",
    "                        **args_list[j])\n",
    "                    \n",
    "                else:\n",
    "                    print('\\n\\nWarning: Not writing detection limit file.' \n",
    "                            'Calculating detection limit does not make sense'\n",
    "                            ' except on background-corrected data. Raw data files' \n",
    "                            ' contain an estimate of detection limit without bg'\n",
    "                            ' correction.\\n')\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = Path('../data/processed/basaltic_glasses/calczaf_files/D2872/')\n",
    "\n",
    "helper_funs.check_calczaf_folder_exists(folderpath)\n",
    "valence_file = sorted(folderpath.glob('valence*'))[0]\n",
    "\n",
    "results = calczaf.process_calczaf_outputs(folderpath, valence_file)\n",
    "\n",
    "# For detection limits\n",
    "\n",
    "results_detlim = calczaf.process_calczaf_outputs(folderpath / 'detlim/', valence_file, detlim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_by_method = pd.DataFrame(\n",
    "    {\"comment\": datalist[\"comment\"],\n",
    "     \"N wt\": results[\"wtdata\"][\"D2872_3_bg_apf\"].loc[\"N\", :]\n",
    "     }\n",
    "     )\n",
    "\n",
    "N_by_method[\"method\"] = N_by_method[\"comment\"].str.replace(r'_[0-9]+$', '', regex=True)\n",
    "N_by_method.groupby(\"method\")[\"N wt\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's interesting. So for sure, the 100 nA, 30 micron method gave us more nitrogen than the other methods.\n",
    "Does this indicate that nitrogen was lost in all the other methods? Quite probably.\n",
    "\n",
    "Shame I only got three analyses of these but that's okay. \n",
    "\n",
    "Or is it for sure? Maybe it's just variability in the sample?\n",
    "\n",
    "After, some other spots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_by_method.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_summary = {}\n",
    "for nm in results[\"wtdata\"].keys():\n",
    "    n_summary[nm] = results[\"wtdata\"][nm].loc[\"N\", [\"average\", \"stdev\"]]\n",
    "    n_summary[nm].rename({\"stdev\": \"stdev (multiple measurements)\"}, inplace=True)\n",
    "    # n_summary[nm][\"typical stdev on individual measurement\"] = (\n",
    "    #     n_summary[nm][\"average\"] * \n",
    "    #     typical_kratios\n",
    "    #     .loc[nm, \"Stdev % (relative)\"]/100\n",
    "    # )\n",
    "\n",
    "pd.concat(n_summary, axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_pct_summary_table = pd.concat(\n",
    "    {k: v[[\"average\", \"stdev\"]] for k, v in results[\"wtdata\"].items()},\n",
    "    axis=1\n",
    "    ).round(2)\n",
    "\n",
    "wt_pct_summary_table.to_csv(\"../data/processed/hyalophane_StA/wt_pct_summary_GaNcalib.csv\")\n",
    "\n",
    "wt_pct_summary_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n_epma_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
